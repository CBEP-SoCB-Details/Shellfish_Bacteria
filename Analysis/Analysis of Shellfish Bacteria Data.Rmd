---
title: "Analysis of Shellfish Pathogen Data"
output: html_notebook
---

# Load Libraries
```{r}
library(readr)
library(fitdistrplus)
library(maxLik)
library(EnvStats)
library(tidyverse)
```


# Load Data
```{r}
sibfldnm <- 'Derived Data'
parent <- dirname(getwd())
sibling <- file.path(parent,sibfldnm)
fl1<- "Shellfish data 2015 2018.csv"
path <- file.path(sibling, fl1)

coli_data <- read_csv(path, 
    col_types = cols(SDate = col_date(format = "%Y-%m-%d"), 
        SDateTime = col_datetime(format = "%Y-%m-%d %H:%M:%S"), 
        STime = col_time(format = "%H:%M:%S"))) %>%
  mutate_at(c(4:10), factor) %>%

  mutate(WDIR =factor(WDIR, levels = c("CL", "N", "NE",
                                      "E","SE", "S","SW",
                                      "W", "NW"))) %>%
  mutate(Class = factor(Class, levels = c( 'A', 'CA', 'CR',
                                           'R', 'P', 'X' ))) %>%
  mutate(Tide = factor(Tide, levels = c("L", "LF", "F", "HF",
                                        "H", "HE", "E", "LE")))
```


# Data Structure
```{r}
with(coli_data, length(ColiVal))
with(coli_data, sum(is.na(ColiVal)))
```
what does it mean to have missing values in this context?  That is not entirely clear, but these appear to be samples that are recorded with all of the site informaiton, but none of the sample-related informaiton, so my guess is, these represent samples that were scheduleed bun not actually collected.

That suggests we should simply drop these rows as uninformative.
# Exploratory Graphics
```{r}
ggplot(coli_data, aes(SDateTime, ColiVal)) + geom_point(aes(color=LCFlag | RCFlag)) +
  scale_y_log10()
```
So, what this shows us is that we need to address censoring, but principally on the low end.  Interestingly, there are some low values that did not get flagged as censored.  That may reflect the way I determined whether a sample was censored -- by looking for a less than sign in the original data.  I could have alternatively looked at whether the araw col and coli score values were identical.

Note also that the distribution is still skewed, even on a log scale -- this suggests a lognormal density is not really appropriate for these data

```{r}
ggplot(coli_data, aes(SDateTime, ColiVal)) + geom_point(aes(color=GROW_AREA)) +
  scale_y_log10()
```

So lets go to the the trouble of reshaping our data the way we really want...
```{r}
coli_data %>%
  filter(! is.na(ColiVal)) %>%
  group_by(GROW_AREA, YEAR) %>%
  summarize(gmColi = 10^(mean(log10(ColiVal)))) %>%
  ggplot(aes(GROW_AREA, gmColi, group=YEAR)) + geom_col(position=position_dodge())
```
So, geometric means vary slightly year to year and site to site.  This might have been clearer as a line chart by Grow Areas....
```{r}
coli_data %>%
  filter(! is.na(ColiVal)) %>%
  group_by(GROW_AREA, YEAR) %>%
  summarize(gmColi = 10^(mean(log10(ColiVal)))) %>%
  ggplot(aes(YEAR, gmColi, color=GROW_AREA)) + geom_line(lwd=2)
```

Yeah, that's more informative, although without variation  metrics it's only partial.


# Dealing with Skewed Data
The data is so highly skewed that even the logs look skewed, which suggests we may have a hard time finding a nice data distribution.  Lets look at some histograms and potential distributions for modeling the data.

```{r}
ggplot(coli_data, aes(ColiVal)) + geom_histogram(aes(color=RCFlag | LCFlag), bins = 100) +
  scale_x_log10() + scale_y_log10()
```
So, Gamma, Exponential, and perhaps PAreto distributions might work, but gamma is probably the best to try first, since it's easy to work with statistically (and exponential is a special case).

## Gamma Distribution
Gamma can be fit by the methos of moments 

μ^=αθ,σ^2=αθ2

SO, our moments are 
```{r}
(a <- with(coli_data, list(mean=mean(ColiVal, na.rm=TRUE), var=var(ColiVal, na.rm=TRUE))))
```
So, by those last formulas, Theta = Var/Mean
```{r}
(theta = a$var/a$mean)
```

now, alpha = mean/theta
```{r}
(alpha = a$mean/theta)
```
```{r}
tmp <- tibble(x=seq(0,1,0.005), y=dgamma(seq(0,1,0.005),alpha, theta))
ggplot(tmp, aes(x,y)) + geom_line()
```
So, that did not work very well.  What's going on? Perhaps we need to write a real ML fitting function.  Or did I make a dumb mathematical error?

### LOg Likelihood Function
Here I write a simple function that only addresses left censoring.  This is enough to test the model.  We wil luse this with the maxLik function to estimate parameter values.
```{r}
loglikGamma <- function(params, values, flags)
{
  shape = params[1]
  rate = params[2]
  
  if (shape<=0) return(NA)
  if (rate<=0) return(NA)
        
  ll <- sum(if_else(flags,
                  pgamma(values, shape,rate, log.p = TRUE),  # Total density below DL
                  dgamma(values, shape, rate, log=TRUE)) )   # Density for other obs
    return(ll)
}
  
```

### lets test that on simulated data
```{r}
simdat <- rgamma(200, 0.1, .01)
censored <- simdat<0.05
simdat <- ifelse(censored, 0.05, simdat)

ggplot(data = tibble(simdat), aes(x=simdat)) + geom_histogram(aes(color=censored))
```
But note that half of simulated samples are censored.
```{r}
sum(censored)/200
```
```{r}
fit <- maxLik( loglikGamma, start=c(shape=.1,rate=.1), values= simdat,flags= censored)
fit

```

### Apply it to Real Data
```{r}
fit <- maxLik( loglikGamma, start=c(shape=.1,rate=.1), values= coli_data$ColiVal,flags= coli_data$LCFlag)
fit
```
SO, it looks like the maxlik package can't handle this as a gamma distribution.

A Special case would be to assume an exponential distribution.  The mean of the exponential distribution is 1/rate, suggestin the rate parameter would be the reciprocal of the mean.
```{r}
tmp <- tibble(x=seq(0,100,0.5), y=dexp(seq(0,100,.5),1/17))
ggplot(tmp, aes(x,y)) + geom_line()
```
Which is nowhere near steep enough for our data, so clearly no good.

# Pareto distribution
The PAreto distribution is an extreme value distribution.  it is a two parameter family, with Scale and Shape parameters, both must be positive.

Significantly, the Pareto Distribution ends up looking linear on a log-log plot, suggesting this may be a good bet for the bacteria data.

This can be fit a couple of different ways.  First and second moments have relatively simple closed form values, so parameters can be estimated using either the method of mopments, or maximum likelihood methods.

Some comments on closed-form maximum likelihood estimates based on sample moments can be found here:
https://stats.stackexchange.com/questions/27426/how-do-i-fit-a-set-of-data-to-a-pareto-distribution-in-r
The Pareto distribution is not available in vanilla R, although it is availalbe in many packages. See https://cran.r-project.org/web/views/Distributions.html

## Direct Fitting of (non-censored) data
Here is the simple function offered there to estimate distribution parameters (for non-censored data):
```{r}
pareto.MLE <- function(X)
{
   n <- length(X)
   m <- min(X, na.rm=TRUE)
   a <- n/sum(log(X)-log(m), na.rm=TRUE)
   return( c(m,a)) 
}

pareto.MLE(coli_data$ColiVal)
```
We can use the Pareto functions from the EnvStats package to work with the Pareto distrobution.  That package has lots of other nice features for environmental analysis, so is worth exploring for other reasons too.
```{r}
densityvals <- tibble(x = seq(1,1000,.1), y= dpareto(seq(1,1000,.1), 1.9, 1.675))

ggplot(coli_data, aes(ColiVal)) +
  geom_density() +
  geom_line(data = densityvals,  aes(x=x, y=y), color = 'orange') +
  scale_x_log10(limits=c(1,50)) +
  ylim(c(0,2))

```
So, we're on the right track, but not dealing with censoring is causing problems. This distribution has no values below 1.9,although we know there should be such observations were data not censored.  Even those 1.9 values are an artifact of how the data were interpreted.  Those are almost certainly really censored values that should be 2.0.  Also, the discrete nature of low values is problematic. This is really "interval censored data" if we want to get technical.  A range of potential observations are pooled into specific aggregate estimated values.

Note that the observed "density" values -- which should be bounded by zero and one -- exceed one because of the discrete nature of observables in those lower values.

So, we need to address censoring.

### LOg Likelihood Function
We can write our own fitting function that addresses censoring.  We'll follow the usual maximum liklihood approach, although I suspect this may not perform well with a heavy-tailed distribution.

The following funbction should be enough to test the model.  We will use this with the maxLik function to estimate parameter values.
```{r}
loglikPareto <- function(params, values, lflags, rflags=NULL)
{
  scale = params[1]
  shape = params[2]
  
  if (scale<=0) return(NA)
  if (shape<=0) return(NA)
    
  
  if (is.null(rflags))
    {
      ll <- sum(if_else(lflags,
                  pgamma(values, scale, shape, log.p = TRUE),  # Total density below DL
                  dgamma(values, scale, shape, log=TRUE)) )    # Density for other obs
      return(ll)
    }
  else
    {
      lv <- if_else(lflags,
                  pgamma(values, scale, shape, log.p = TRUE),  # Total density below DL
                  dgamma(values, scale, shape, log=TRUE))   # Density for other obs
      lv <- ifelse(rflags, pgamma(values, scale, shape, lower.tail=False, log.p = TRUE),  # Total above DL,
                   lv )
                   
      return(sum(lv))
    }
}
  
```

### lets test that on simulated data
```{r}
simdat <- rpareto(2000, 1, 1.5)
censored <- simdat<2
simdat <- ifelse(censored, 2, simdat)

ggplot(data = tibble(simdat), aes(x=simdat)) + geom_histogram(aes(color=censored), binwidth = .05) +
  scale_x_log10() +scale_y_log10()
```
That gives a pretty good idea of what a plot of a PAreto Distribution might look like.

```{r}
fit <- maxLik( loglikPareto, start=c(scale=1,shape=1), values= simdat, lflags=censored)
fit
```
RESULTS ARE HIGHLY VARIABLE AND DON'T ALIGN WELL WITH ORIGINAL PARAMETERS....

```{r}
simdata <- tibble(simdat, censored)
densityvals <- tibble(x = seq(1,1000,.1), y= dpareto(seq(1,1000,.1), .43, .21))

ggplot(simdata, aes(simdat)) +
  geom_histogram(aes(y=..density..), bins=1000) +
  geom_line(data = densityvals,  aes(x=x, y=y), color = 'orange') +
  scale_x_log10() +
  scale_y_log10()
```
This is clearly a muisunderstanding of how to plot distributions and histograms at the same time....

# fitdistrplus Package
fitdistrplus provides general functions for fitting standard as wel las non-standard distributions.
```{r}
test_dat <- coli_data %>%
  filter(! is.na(ColiVal)) %>%
  dplyr::select(ColiVal, LCFlag, RCFlag)
plotdist(test_dat$ColiVal, histo = TRUE, demp = TRUE)
```

```{r}
descdist(test_dat$ColiVal, boot = 1000)
```
That plot confirm that the real data has heavier tails than either lognormal or gamma distributions  A Beta distribution is not appropriate here, since Beta veriates are bounded between zero and one.  The figure does not show a range of skewness/kurtosis values for a Pareto distribution, but it is at least a reasonable, heavy tailed, highly skewed distribution. 

## Fit a Pareto Distribution
Simple application of default maximum likelihood does not work here.
```{r error = TRUE}
f <- fitdist(test_dat$ColiVal, "pareto", start = list(location=1, shape=1.5))
f
```
The function provides three other approaches to fitting a distribution :  "mme" for 'moment matching estimation', "qme" for 'quantile matching estimation' and "mge" for 'maximum goodness-of-fit estimation'.  Each of these other methods requires additional prameters to run.

Using a maximizing goodness of fit method works, with only a "start" parameter.  The default distance metric here is Cramer-von Mises distance, but other options are available.
```{r}
f1 <- fitdist(test_dat$ColiVal, "pareto", method='mge', start = list(location=1, shape=1.5))
cat('\n')
f1$estimate
```

Quantile matching fits also work, with a list of quantiles to be matched. Since we have two parameters to fit, we can ask for fits at two quantiles. It's not obvious statistically what qunatiles make the most sense, but the shellfish sanitation program is interested in the median and the p90, so lets go with those.  
```{r}
f2 <- fitdist(test_dat$ColiVal, "pareto", method='qme', probs=c(.50, .90), start = list(location=1, shape=1.5))
cat('\n')
f2$estimate
```

The results are quite a bit different from the prior estimate, which is troubling, but may only reflect the impact of censoring on the estimates.

The moment matching estimation requires a function for estimating the moments of the distribution.  THAt is not provided by EnvStats. We could roll our own, but we have two suitable fitting methods already.
```{r error = TRUE}
f3 <- fitdist(test_dat$ColiVal, "pareto", method='mme', order=c(1,2), start = list(location=1, shape=1.5))
f3
```

## Plot results of those two fits

```{r}
plot(f1)
```

```{r}
plot(f2)
```
So, those actually looks pretty good, other than the censoring.

But we need to address the censoring, which is not trivial here.

# Fitting a PAreto Distribution to Censored Data
The FAQ file for the fitdistplus files says hte following about fitting censored data (function)here, with the fitdistcens function):

> Censored data must be represented in the package by a dataframe of two columns respectively named left and right, describing each observed value as an interval. The left column contains either NA for left censored observations, the left bound of the interval for interval censored observations, or the observed value for non-censored observations. The right column contains either NA for right censored observations, the right bound of the interval for interval censored observations, or the observed value for non-censored observations.

So, we need to address several cases here for censoring:

1.  Values below 2.0
2.  Discrete nature of values reported by the sampling method, especially at lower values
3.  Right cenesored values that exceed the method upper limit

## What values are represented in our data?
```{r}
plot(as.numeric(levels(factor(coli_data$ColiVal))))
```
So, are we dealing with discrete or continuous variables here?
```{r}
sum(coli_data$ColiVal != as.integer(coli_data$ColiVal), na.rm=TRUE)
```
Most of our observations are integers, but not all.

```{r}
levels(factor(coli_data$ColiVal[which(coli_data$ColiVal != as.integer(coli_data$ColiVal))]))
```
These are discrete but non-integer values.  What do we do with these?  We can't go to a geometric distribution, which assumed interger values, not to a pareto distribution, which assumes continuous values.


WHat is the skewness of a geompetric distribution?  Would that be a better fit for these data?  How does a geometric distribution plot oin a log-log plot?

